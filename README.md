# <img src="images/logo_Mono3DVG.png" height="40"> Mono3DVG: 3D Visual Grounding in Monocular Images
<p align="center">
    <img src="https://i.imgur.com/waxVImv.png" alt="Oryx Video-ChatGPT">
</p>

##### Author: Yang Zhan
This is the official repository for paper **"Mono3DVG: 3D Visual Grounding in Monocular Images"**.

## Please share a <font color='orange'>STAR â­</font> if this project does help


## ğŸ“¢ Latest Updates
- **Dec-09-2023**: Mono3DVG paper is accepted by AAAI2024. ğŸ”¥ğŸ”¥
- ğŸ“¦ Code, models, and datasets coming soon! ğŸš€
---

## ğŸ’¬ Mono3DVG: 3D Visual Grounding in Monocular Images
introduction


## <img src="images/logo_Mono3DVG.png" height="20"> Mono3DVG : Architecture

An Overview of Mono3DVG


## ğŸ‘ï¸ Visualization
images


## ğŸ” Results
tables


## ğŸ“œ Citation
```bibtex
@misc{*,
      title={}, 
      author={},
      year={2023},
      archivePrefix={arXiv}
}  
```

## ğŸ™ Acknowledgement
Our code is based on (ICCV 2023)[MonoDETR](https://github.com/ZrrSkywalker/MonoDETR). We sincerely appreciate their contributions and authors for releasing source codes. I would like to thank Xiong zhitong and Yuan yuan for helping the manuscript. I also thank the School of Artificial Intelligence, OPtics, and ElectroNics (iOPEN), Northwestern Polytechnical University for supporting this work.


