# <img src="images/logo_Mono3DVG.png" height="40"> Mono3DVG: 3D Visual Grounding in Monocular Images
<p align="center">
    <img src="https://i.imgur.com/waxVImv.png" alt="Oryx Video-ChatGPT">
</p>

##### Author: Yang Zhan
This is the official repository for paper **"Mono3DVG: 3D Visual Grounding in Monocular Images"**.

## Please share a <font color='orange'>STAR ⭐</font> if this project does help


## 📢 Latest Updates
- **Dec-09-2023**: Mono3DVG paper is accepted by AAAI2024. 🔥🔥
- 📦 Code, models, and datasets coming soon! 🚀
---

## 💬 Mono3DVG: 3D Visual Grounding in Monocular Images
introduction


## <img src="images/logo_Mono3DVG.png" height="20"> Mono3DVG : Architecture

An Overview of Mono3DVG


## 👁️ Visualization

<div align="center">
  <img src="images/1-results.png"/>
</div>

<div align="center">
  <img src="images/results_maps.png"/>
</div>

<div align="center">
  <img src="images/2-results.png"/>
</div>
<div align="center">
  <img src="images/2-results2.png"/>
</div>

<div align="center">
  <img src="images/3-results.png"/>
</div>
<div align="center">
  <img src="images/3-results2.png"/>
</div>

<div align="center">
  <img src="images/4-results.png"/>
</div>
<div align="center">
  <img src="images/4-results2.png"/>
</div>


## 🔍 Results
tables


## 📜 Citation
```bibtex
@misc{*,
      title={}, 
      author={},
      year={2023},
      archivePrefix={arXiv}
}  
```

## 🙏 Acknowledgement
Our code is based on (ICCV 2023)[MonoDETR](https://github.com/ZrrSkywalker/MonoDETR). We sincerely appreciate their contributions and authors for releasing source codes. I would like to thank Xiong zhitong and Yuan yuan for helping the manuscript. I also thank the School of Artificial Intelligence, OPtics, and ElectroNics (iOPEN), Northwestern Polytechnical University for supporting this work.

## 🤖 Contact
If you have any questions about this project, please feel free to contact zhanyangnwpu@gmail.com.
